{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f7777368d3f847e7a674dd3569e5a8c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eff4a6198f114c41a02d01214c350f11",
              "IPY_MODEL_a2060c8608f74969a283a0e527e13233",
              "IPY_MODEL_8e7d1fe02d564769898ff842d488b736"
            ],
            "layout": "IPY_MODEL_0b8a0efa5c4d429ab9c9dfd4c3d77e4b"
          }
        },
        "eff4a6198f114c41a02d01214c350f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4024f4f9f7434350b2f25f9f7518f587",
            "placeholder": "​",
            "style": "IPY_MODEL_7ca7395a8fdd46a4bdeb7f86bdcce21a",
            "value": "100%"
          }
        },
        "a2060c8608f74969a283a0e527e13233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02ddcc8f30a042ebb2c1bafec0671479",
            "max": 350282127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40d8ababe4404c088a87af33c79e4927",
            "value": 350282127
          }
        },
        "8e7d1fe02d564769898ff842d488b736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_612e3b25c24f44b5b9bb0662006fa5a1",
            "placeholder": "​",
            "style": "IPY_MODEL_89aba7823b124379be51968a6302710f",
            "value": " 334M/334M [00:20&lt;00:00, 14.9MB/s]"
          }
        },
        "0b8a0efa5c4d429ab9c9dfd4c3d77e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4024f4f9f7434350b2f25f9f7518f587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ca7395a8fdd46a4bdeb7f86bdcce21a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02ddcc8f30a042ebb2c1bafec0671479": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40d8ababe4404c088a87af33c79e4927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "612e3b25c24f44b5b9bb0662006fa5a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89aba7823b124379be51968a6302710f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mathindata/SQL_Sandbox/blob/master/dadmatoools_00.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pDOcXX5NlAf"
      },
      "source": [
        "# **DadmaTools:  A Python NLP Library for Persian**\n",
        "1. Download the toolkit via `pip`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxDKOne0uGBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "466cd200-3e70-4d8d-89e7-7ab440c3f79f"
      },
      "source": [
        "!pip install dadmatools"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dadmatools\n",
            "  Downloading dadmatools-1.5.2-py3-none-any.whl (862 kB)\n",
            "\u001b[K     |████████████████████████████████| 862 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting html2text\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: spacy>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from dadmatools) (3.4.1)\n",
            "Collecting conllu\n",
            "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: gdown>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from dadmatools) (4.4.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from dadmatools) (1.12.1+cu113)\n",
            "Collecting supar==1.1.2\n",
            "  Downloading supar-1.1.2-py3-none-any.whl (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 7.8 MB/s \n",
            "\u001b[?25hCollecting hyperopt>=0.2.5\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 49.6 MB/s \n",
            "\u001b[?25hCollecting Deprecated==1.2.6\n",
            "  Downloading Deprecated-1.2.6-py2.py3-none-any.whl (8.1 kB)\n",
            "Collecting bpemb>=0.3.3\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: gensim>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from dadmatools) (3.6.0)\n",
            "Requirement already satisfied: folium>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from dadmatools) (0.12.1.post1)\n",
            "Collecting pytorch-transformers>=1.1.0\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[K     |████████████████████████████████| 176 kB 63.6 MB/s \n",
            "\u001b[?25hCollecting h5py>=3.3.0\n",
            "  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 55.7 MB/s \n",
            "\u001b[?25hCollecting py7zr>=0.17.2\n",
            "  Downloading py7zr-0.20.0-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting sklearn>=0.0\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.6 in /usr/local/lib/python3.7/dist-packages (from dadmatools) (0.8.10)\n",
            "Collecting transformers>=4.9.1\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 43.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from dadmatools) (3.7)\n",
            "Collecting NERDA\n",
            "  Downloading NERDA-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 65.1 MB/s \n",
            "\u001b[?25hCollecting pyconll>=3.1.0\n",
            "  Downloading pyconll-3.1.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated==1.2.6->dadmatools) (1.14.1)\n",
            "Collecting stanza\n",
            "  Downloading stanza-1.4.2-py3-none-any.whl (691 kB)\n",
            "\u001b[K     |████████████████████████████████| 691 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from supar==1.1.2->dadmatools) (0.3.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.3->dadmatools) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.3->dadmatools) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.3->dadmatools) (1.21.6)\n",
            "Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from folium>=0.2.1->dadmatools) (0.5.0)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from folium>=0.2.1->dadmatools) (2.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=4.3.1->dadmatools) (3.8.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown>=4.3.1->dadmatools) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown>=4.3.1->dadmatools) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.6.0->dadmatools) (1.7.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.6.0->dadmatools) (5.2.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.5->dadmatools) (2.6.3)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 74.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.5->dadmatools) (0.16.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.5->dadmatools) (1.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.9->folium>=0.2.1->dadmatools) (2.0.1)\n",
            "Collecting texttable\n",
            "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pyppmd<0.19.0,>=0.18.1\n",
            "  Downloading pyppmd-0.18.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 68.6 MB/s \n",
            "\u001b[?25hCollecting brotli>=1.0.9\n",
            "  Downloading Brotli-1.0.9-cp37-cp37m-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[K     |████████████████████████████████| 357 kB 68.1 MB/s \n",
            "\u001b[?25hCollecting pycryptodomex>=3.6.6\n",
            "  Downloading pycryptodomex-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 56.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from py7zr>=0.17.2->dadmatools) (4.12.0)\n",
            "Collecting inflate64>=0.3.0\n",
            "  Downloading inflate64-0.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 13.0 MB/s \n",
            "\u001b[?25hCollecting pyzstd>=0.14.4\n",
            "  Downloading pyzstd-0.15.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (379 kB)\n",
            "\u001b[K     |████████████████████████████████| 379 kB 69.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from py7zr>=0.17.2->dadmatools) (5.4.8)\n",
            "Collecting multivolumefile>=0.2.3\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting pybcj>=0.6.0\n",
            "  Downloading pybcj-1.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 57.3 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.24.86-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 60.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers>=1.1.0->dadmatools) (2022.6.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn>=0.0->dadmatools) (1.0.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (3.3.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (4.1.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (21.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (1.0.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (1.9.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (1.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (2.4.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (3.0.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (8.1.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (3.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (2.0.6)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (0.4.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (2.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->dadmatools) (0.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.0->dadmatools) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.0.0->dadmatools) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.0.0->dadmatools) (0.7.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.9.1->dadmatools) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 52.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 68.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=3.0.0->dadmatools) (7.1.2)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.0 MB/s \n",
            "\u001b[?25hCollecting botocore<1.28.0,>=1.27.86\n",
            "  Downloading botocore-1.27.86-py3-none-any.whl (9.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2 MB 47.4 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 71.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.86->boto3->pytorch-transformers>=1.1.0->dadmatools) (2.8.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from NERDA->dadmatools) (1.3.5)\n",
            "Collecting progressbar\n",
            "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->dadmatools) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->NERDA->dadmatools) (2022.2.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.3->dadmatools) (1.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn>=0.0->dadmatools) (3.1.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza->supar==1.1.2->dadmatools) (3.17.3)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.1.0.tar.gz (216 kB)\n",
            "\u001b[K     |████████████████████████████████| 216 kB 69.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: sklearn, progressbar, sacremoses, emoji\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=f612159ac92ca7665959a292de5dc94602a28c5bef45a1cf1702d4b9ad2c4388\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12082 sha256=58aaf302866d40a4cd20c69ee2a21d3565c472245699d84737a5ff7ae0594ba6\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/fd/1f/3e35ed57e94cd8ced38dd46771f1f0f94f65fec548659ed855\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=8e51e7930b3cb83a04c9927f6545f3b1f38a52ccde3d474c327a264927c00219\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.1.0-py3-none-any.whl size=212392 sha256=dc4e91665962fb951a4f56a1e1df015e27aa836e98f10bdbecc9afb4a44282fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/75/99/51c2a119f4cfd3af7b49cc57e4f737bed7e40b348a85d82804\n",
            "Successfully built sklearn progressbar sacremoses emoji\n",
            "Installing collected packages: urllib3, jmespath, botocore, tokenizers, s3transfer, huggingface-hub, emoji, transformers, texttable, stanza, sklearn, sentencepiece, sacremoses, pyzstd, pyppmd, pycryptodomex, pyconll, pybcj, py4j, progressbar, multivolumefile, inflate64, brotli, boto3, tf-estimator-nightly, supar, segtok, pytorch-transformers, py7zr, NERDA, hyperopt, html2text, h5py, Deprecated, conllu, bpemb, dadmatools\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed Deprecated-1.2.6 NERDA-1.0.0 boto3-1.24.86 botocore-1.27.86 bpemb-0.3.4 brotli-1.0.9 conllu-4.5.2 dadmatools-1.5.2 emoji-2.1.0 h5py-3.7.0 html2text-2020.1.16 huggingface-hub-0.10.0 hyperopt-0.2.7 inflate64-0.3.0 jmespath-1.0.1 multivolumefile-0.2.3 progressbar-2.5 py4j-0.10.9.7 py7zr-0.20.0 pybcj-1.0.1 pyconll-3.1.0 pycryptodomex-3.15.0 pyppmd-0.18.3 pytorch-transformers-1.2.0 pyzstd-0.15.3 s3transfer-0.6.0 sacremoses-0.0.53 segtok-1.5.11 sentencepiece-0.1.97 sklearn-0.0 stanza-1.4.2 supar-1.1.2 texttable-1.6.4 tf-estimator-nightly-2.8.0.dev2021122109 tokenizers-0.12.1 transformers-4.22.2 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7uIzpjcN2K9"
      },
      "source": [
        "DadmaTools has different NLP models: *normalizer, tokenizer, lemmatizer, pos tagger, dependancy parser, and constituency parser.*\n",
        "\n",
        "The normalizer can be used with the code below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7P72ttdCGC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea76d33-9443-47fc-fee2-56f0751c60f7"
      },
      "source": [
        "from dadmatools.models.normalizer import Normalizer\n",
        "\n",
        "normalizer = Normalizer(\n",
        "    full_cleaning=False,\n",
        "    unify_chars=True,\n",
        "    refine_punc_spacing=True,\n",
        "    remove_extra_space=True,\n",
        "    remove_puncs=False,\n",
        "    remove_html=False,\n",
        "    remove_stop_word=False,\n",
        "    replace_email_with=\"<EMAIL>\",\n",
        "    replace_number_with=None,\n",
        "    replace_url_with=\"\",\n",
        "    replace_mobile_number_with=None,\n",
        "    replace_emoji_with=None,\n",
        "    replace_home_number_with=None\n",
        ")\n",
        "\n",
        "text = \"\"\"\n",
        "<p>\n",
        "دادماتولز اولین نسخش سال ۱۴۰۰ منتشر شده. \n",
        "امیدواریم که این تولز بتونه کار با متن رو براتون شیرین‌تر و راحت‌تر کنه\n",
        "لطفا با ایمیل dadmatools@dadmatech.ir با ما در ارتباط باشید\n",
        "آدرس گیت‌هاب هم که خب معرف حضور مبارک هست:\n",
        " https://github.com/Dadmatech/DadmaTools\n",
        "</p>\n",
        "\"\"\"\n",
        "print('input text : ', text)\n",
        "print('output text when replace emails and remove urls : ', normalizer.normalize(text))\n",
        "\n",
        "#full cleaning\n",
        "normalizer = Normalizer(full_cleaning=True)\n",
        "print('output text when using full_cleaning parameter', normalizer.normalize(text))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input text :  \n",
            "<p>\n",
            "دادماتولز اولین نسخش سال ۱۴۰۰ منتشر شده. \n",
            "امیدواریم که این تولز بتونه کار با متن رو براتون شیرین‌تر و راحت‌تر کنه\n",
            "لطفا با ایمیل dadmatools@dadmatech.ir با ما در ارتباط باشید\n",
            "آدرس گیت‌هاب هم که خب معرف حضور مبارک هست:\n",
            " https://github.com/Dadmatech/DadmaTools\n",
            "</p>\n",
            "\n",
            "output text when replace emails and remove urls :  <p> دادماتولز اولین نسخش سال 1400 منتشر شده. امیدواریم که این تولز بتونه کار با متن رو براتون شیرین‌تر و راحت‌تر کنه لطفا با ایمیل <EMAIL> با ما در ارتباط باشید آدرس گیت‌هاب هم که خب معرف حضور مبارک هست: </p>\n",
            "output text when using full_cleaning parameter دادماتولز نسخش سال منتشر تولز بتونه کار متن براتون شیرین‌تر راحت‌تر کنه ایمیل ارتباط آدرس گیت‌هاب معرف حضور مبارک\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUsCTrjtO8gT"
      },
      "source": [
        "**Other NLP models can be used via pipeline. Each task has its own abbreviation.** "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1hsYa6C67DW",
        "outputId": "83945a64-ed09-47dd-d82e-4a380ce2a471"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:24\n",
            "🔁 Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install cudnn=8.3.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1vTNjbU7MCj",
        "outputId": "e153dcf8-c687-4922-f9b2-cf7bf7627f46"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Collecting package metadata (repodata.json): / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.14.0\n",
            "  latest version: 22.9.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - cudnn=8.3.2\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2022.9.24  |       ha878542_0         150 KB  conda-forge\n",
            "    certifi-2022.9.24          |     pyhd8ed1ab_0         155 KB  conda-forge\n",
            "    cudatoolkit-11.1.1         |      ha002fc5_10        1.20 GB  conda-forge\n",
            "    cudnn-8.3.2.44             |       hed8a83a_1       623.1 MB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        1.81 GB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  cudatoolkit        conda-forge/linux-64::cudatoolkit-11.1.1-ha002fc5_10\n",
            "  cudnn              conda-forge/linux-64::cudnn-8.3.2.44-hed8a83a_1\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                      2022.6.15-ha878542_0 --> 2022.9.24-ha878542_0\n",
            "  certifi            conda-forge/linux-64::certifi-2022.6.~ --> conda-forge/noarch::certifi-2022.9.24-pyhd8ed1ab_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "ca-certificates-2022 | 150 KB    | : 100% 1.0/1 [00:00<00:00,  6.18it/s]                \n",
            "cudnn-8.3.2.44       | 623.1 MB  | : 100% 1.0/1 [01:22<00:00, 82.92s/it]               \n",
            "cudatoolkit-11.1.1   | 1.20 GB   | : 100% 1.0/1 [02:42<00:00, 162.04s/it]             \n",
            "certifi-2022.9.24    | 155 KB    | : 100% 1.0/1 [00:00<00:00, 12.71it/s]\n",
            "Preparing transaction: \\ \b\bdone\n",
            "Verifying transaction: / \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ By downloading and using the cuDNN conda packages, you accept the terms and conditions of the NVIDIA cuDNN EULA -\n",
            "  https://docs.nvidia.com/deeplearning/cudnn/sla/index.html\n",
            "\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda update -n base -c conda-forge conda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLDMlz8X-TwK",
        "outputId": "e76f4ec6-c786-4502-a6c0-8d15a87c5e62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - conda\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    conda-22.9.0               |   py37h89c1867_1         960 KB  conda-forge\n",
            "    conda-package-handling-1.9.0|   py37h540881e_0         1.0 MB  conda-forge\n",
            "    cryptography-38.0.1        |   py37h38fbfac_0         1.6 MB  conda-forge\n",
            "    cudatoolkit-11.7.0         |      hd8887f6_10       831.6 MB  conda-forge\n",
            "    idna-3.4                   |     pyhd8ed1ab_0          55 KB  conda-forge\n",
            "    libcurl-7.85.0             |       h7bff187_0         348 KB  conda-forge\n",
            "    libiconv-1.17              |       h166bdaf_0         1.4 MB  conda-forge\n",
            "    libsqlite-3.39.4           |       h753d276_0         803 KB  conda-forge\n",
            "    libxml2-2.10.2             |       h4c7fe37_1         727 KB  conda-forge\n",
            "    libzlib-1.2.12             |       h166bdaf_4          65 KB  conda-forge\n",
            "    pyopenssl-22.0.0           |     pyhd8ed1ab_1         120 KB  conda-forge\n",
            "    requests-2.28.1            |     pyhd8ed1ab_1          53 KB  conda-forge\n",
            "    setuptools-65.4.1          |     pyhd8ed1ab_0         776 KB  conda-forge\n",
            "    sqlite-3.39.4              |       h4ff8645_0         789 KB  conda-forge\n",
            "    tqdm-4.64.1                |     pyhd8ed1ab_0          82 KB  conda-forge\n",
            "    yaml-cpp-0.7.0             |       h27087fc_2         215 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       840.4 MB\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  six-1.16.0-pyh6c4a22f_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  conda                               4.14.0-py37h89c1867_0 --> 22.9.0-py37h89c1867_1\n",
            "  conda-package-han~                   1.8.1-py37h540881e_1 --> 1.9.0-py37h540881e_0\n",
            "  cryptography                        37.0.4-py37h38fbfac_0 --> 38.0.1-py37h38fbfac_0\n",
            "  cudatoolkit                            11.1.1-ha002fc5_10 --> 11.7.0-hd8887f6_10\n",
            "  idna                                     3.3-pyhd8ed1ab_0 --> 3.4-pyhd8ed1ab_0\n",
            "  libcurl                                 7.83.1-h7bff187_0 --> 7.85.0-h7bff187_0\n",
            "  libiconv                                  1.16-h516909a_0 --> 1.17-h166bdaf_0\n",
            "  libsqlite                               3.39.2-h753d276_1 --> 3.39.4-h753d276_0\n",
            "  libxml2                                 2.9.14-h22db469_4 --> 2.10.2-h4c7fe37_1\n",
            "  libzlib                                 1.2.12-h166bdaf_2 --> 1.2.12-h166bdaf_4\n",
            "  pyopenssl                             22.0.0-pyhd8ed1ab_0 --> 22.0.0-pyhd8ed1ab_1\n",
            "  requests                              2.28.1-pyhd8ed1ab_0 --> 2.28.1-pyhd8ed1ab_1\n",
            "  setuptools         conda-forge/linux-64::setuptools-65.3~ --> conda-forge/noarch::setuptools-65.4.1-pyhd8ed1ab_0\n",
            "  sqlite                                  3.39.2-h4ff8645_1 --> 3.39.4-h4ff8645_0\n",
            "  tqdm                                  4.64.0-pyhd8ed1ab_0 --> 4.64.1-pyhd8ed1ab_0\n",
            "  yaml-cpp                                 0.7.0-h27087fc_1 --> 0.7.0-h27087fc_2\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "idna-3.4             | 55 KB     | : 100% 1.0/1 [00:00<00:00,  5.34it/s]               \n",
            "cryptography-38.0.1  | 1.6 MB    | : 100% 1.0/1 [00:00<00:00,  3.04it/s]\n",
            "cudatoolkit-11.7.0   | 831.6 MB  | : 100% 1.0/1 [01:43<00:00, 103.79s/it]              \n",
            "conda-22.9.0         | 960 KB    | : 100% 1.0/1 [00:00<00:00,  4.06it/s]\n",
            "libzlib-1.2.12       | 65 KB     | : 100% 1.0/1 [00:00<00:00, 21.15it/s]\n",
            "tqdm-4.64.1          | 82 KB     | : 100% 1.0/1 [00:00<00:00, 18.42it/s]\n",
            "requests-2.28.1      | 53 KB     | : 100% 1.0/1 [00:00<00:00, 14.74it/s]\n",
            "pyopenssl-22.0.0     | 120 KB    | : 100% 1.0/1 [00:00<00:00, 13.96it/s]\n",
            "conda-package-handli | 1.0 MB    | : 100% 1.0/1 [00:00<00:00,  5.80it/s]\n",
            "setuptools-65.4.1    | 776 KB    | : 100% 1.0/1 [00:00<00:00,  4.93it/s]\n",
            "yaml-cpp-0.7.0       | 215 KB    | : 100% 1.0/1 [00:00<00:00, 11.31it/s]\n",
            "libcurl-7.85.0       | 348 KB    | : 100% 1.0/1 [00:00<00:00, 10.93it/s]\n",
            "sqlite-3.39.4        | 789 KB    | : 100% 1.0/1 [00:00<00:00,  6.22it/s]\n",
            "libxml2-2.10.2       | 727 KB    | : 100% 1.0/1 [00:00<00:00,  7.65it/s]\n",
            "libiconv-1.17        | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  4.76it/s]\n",
            "libsqlite-3.39.4     | 803 KB    | : 100% 1.0/1 [00:00<00:00,  6.57it/s]\n",
            "Preparing transaction: | \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Retrieving notices: ...working... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609,
          "referenced_widgets": [
            "f7777368d3f847e7a674dd3569e5a8c5",
            "eff4a6198f114c41a02d01214c350f11",
            "a2060c8608f74969a283a0e527e13233",
            "8e7d1fe02d564769898ff842d488b736",
            "0b8a0efa5c4d429ab9c9dfd4c3d77e4b",
            "4024f4f9f7434350b2f25f9f7518f587",
            "7ca7395a8fdd46a4bdeb7f86bdcce21a",
            "02ddcc8f30a042ebb2c1bafec0671479",
            "40d8ababe4404c088a87af33c79e4927",
            "612e3b25c24f44b5b9bb0662006fa5a1",
            "89aba7823b124379be51968a6302710f"
          ]
        },
        "id": "VlnZ9dKGR_X0",
        "outputId": "4c729ec8-8107-493a-e0b7-39b526592d7f"
      },
      "source": [
        " import dadmatools.pipeline.language as language\n",
        "\n",
        "# here lemmatizer and pos tagger will be loaded\n",
        "# as tokenizer is the default tool, it will be loaded even without calling\n",
        "# pips = 'lem,pos' \n",
        "# pips = 'dep' \n",
        "pips = 'tok,lem,pos,dep,cons' \n",
        "nlp = language.Pipeline(pips)\n",
        "\n",
        "# you can see the pipeline with this code\n",
        "print(nlp.analyze_pipes(pretty=True))\n",
        "\n",
        "# doc is an SpaCy object\n",
        "doc = nlp('از قصهٔ کودکیشان که می‌گفت، گاهی حرص می‌خورد!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model fa_tokenizer exists in /root/.pernlp/fa_tokenizer.pt\n",
            "Model fa_mwt exists in /root/.pernlp/fa_mwt.pt\n",
            "Model fa_lemmatizer exists in /root/.pernlp/fa_lemmatizer.pt\n",
            "Model parsbert exists in /root/.pernlp/parsbert.tar.gz\n",
            "Model dependencyparser exists in /root/.pernlp/dependencyparser.pt\n",
            "2022-10-05 02:35:23,820 loading file /usr/local/lib/python3.7/dist-packages/dadmatools/saved_models/dependencyparser/dependencyparser.pt\n",
            "Model parsbert exists in /root/.pernlp/parsbert.tar.gz\n",
            "Model postagger exists in /root/.pernlp/postagger.pt\n",
            "2022-10-05 02:35:31,897 loading file /usr/local/lib/python3.7/dist-packages/dadmatools/saved_models/postagger/postagger.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file /root/.pernlp/fa_constituency.pt: : 675MB [00:19, 34.2MB/s]                         \n",
            "Downloading: https://github.com/yzhangcs/parser/releases/download/v1.1.0/ptb.crf.con.lstm.char.zip to /root/.cache/supar/ptb.crf.con.lstm.char.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/334M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7777368d3f847e7a674dd3569e5a8c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "============================= Pipeline Overview =============================\u001b[0m\n",
            "\n",
            "#   Component            Assigns       Requires   Scores   Retokenizes\n",
            "-   ------------------   -----------   --------   ------   -----------\n",
            "0   tokenizer                                              True       \n",
            "                                                                      \n",
            "1   lemmatize            token.lemma                       False      \n",
            "                                                                      \n",
            "2   dependancyparser     token.dep                         False      \n",
            "                                                                      \n",
            "3   postagger            token.pos                         False      \n",
            "                                                                      \n",
            "4   constituencyparser                                     False      \n",
            "\n",
            "\u001b[38;5;2m✔ No problems found.\u001b[0m\n",
            "{'summary': {'tokenizer': {'assigns': [], 'requires': [], 'scores': [], 'retokenizes': True}, 'lemmatize': {'assigns': ['token.lemma'], 'requires': [], 'scores': [], 'retokenizes': False}, 'dependancyparser': {'assigns': ['token.dep'], 'requires': [], 'scores': [], 'retokenizes': False}, 'postagger': {'assigns': ['token.pos'], 'requires': [], 'scores': [], 'retokenizes': False}, 'constituencyparser': {'assigns': [], 'requires': [], 'scores': [], 'retokenizes': False}}, 'problems': {'tokenizer': [], 'lemmatize': [], 'dependancyparser': [], 'postagger': [], 'constituencyparser': []}, 'attrs': {'token.pos': {'assigns': ['postagger'], 'requires': []}, 'token.dep': {'assigns': ['dependancyparser'], 'requires': []}, 'token.lemma': {'assigns': ['lemmatize'], 'requires': []}}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/dadmatools/models/common/beam.py:86: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  prevK = bestScoresId // numWords\n",
            "[2022-10-05 02:36:24,082 INFO] [Ensembling dict with seq2seq lemmatizer...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jdthyt-_PYTS"
      },
      "source": [
        "**Note: the doc object is an spaCy object. To see the result of the pipeline use the** `language.to_json(pips, doc)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JLVUqCC9fRt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8eea73b-440a-41b4-bb88-bff7bf68d46b"
      },
      "source": [
        "output = language.to_json(pips, doc)\n",
        "print(output)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'id': 1, 'text': 'از', 'lemma': 'از', 'pos': 'ADP', 'rel': 'case', 'root': 2}, {'id': 2, 'text': 'قصهٔ', 'lemma': 'قصه', 'pos': 'NOUN', 'rel': 'obl:arg', 'root': 6}, {'id': 3, 'text': 'کودکی', 'lemma': 'کودکی', 'pos': 'NOUN', 'rel': 'nmod', 'root': 2}, {'id': 4, 'text': 'شان', 'lemma': 'آنها', 'pos': 'PRON', 'rel': 'nmod', 'root': 3}, {'id': 5, 'text': 'که', 'lemma': 'که', 'pos': 'SCONJ', 'rel': 'mark', 'root': 6}, {'id': 6, 'text': 'می\\u200cگفت', 'lemma': 'گفت#گو', 'pos': 'NOUN', 'rel': 'acl', 'root': 4}, {'id': 7, 'text': '،', 'lemma': '،', 'pos': 'PUNCT', 'rel': 'punct', 'root': 6}, {'id': 8, 'text': 'گاهی', 'lemma': 'گاه', 'pos': 'NOUN', 'rel': 'obl', 'root': 10}, {'id': 9, 'text': 'حرص', 'lemma': 'حرص', 'pos': 'NOUN', 'rel': 'compound:lvc', 'root': 10}, {'id': 10, 'text': 'می\\u200cخورد', 'lemma': 'خورد#خور', 'pos': 'NOUN', 'rel': 'ccomp', 'root': 6}, {'id': 11, 'text': '!', 'lemma': '!', 'pos': 'NOUN', 'rel': 'punct', 'root': 10}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKtLA9ZKP5C0"
      },
      "source": [
        "The `doc` object has its own extentions. The code below shows the exact attributes of this object.\n",
        "\n",
        "To see the result of `constituency parses` and `chunks` use the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unEl7RSxS51a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3464a83-2f4c-48a7-a1d1-6b377c3c208a"
      },
      "source": [
        "sentences = doc._.sentences\n",
        "for sentence in sentences:\n",
        "    text = sentence.text\n",
        "    for token in sentence:\n",
        "        token_text = token.text\n",
        "        lemma = token.lemma_\n",
        "        pos_tag = token.pos_\n",
        "        dep = token.dep_\n",
        "        dep_arc = token._.dep_arc\n",
        "sent_constituency = doc._.constituency\n",
        "sent_chunks = doc._.chunks\n",
        "print(sent_constituency)\n",
        "print(sent_chunks)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(TOP (NP (_ از) (_ قصهٔ) (_ کودکی) (_ شان) (_ که) (NP (_ می‌گفت) (NP (_ ،) (NP (_ گاهی) (NP (_ حرص) (_ می‌خورد))))) (_ !)))]\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the ner, call the `ner` in pipeline. See the result as below."
      ],
      "metadata": {
        "id": "YRiqsbtuWKDZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoRmz9nW0_9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f94224-bf6b-4401-ecd1-e1b132710ac1"
      },
      "source": [
        "pips = 'ner' \n",
        "nlp = language.Pipeline(pips)\n",
        "doc = nlp('این سریال به صورت رسمی در تاریخ دهم می ۲۰۱۱ توسط علی مرادی برای پخش رزرو شد!')\n",
        "print(doc._.ners)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model fa_tokenizer exists in /root/.pernlp/fa_tokenizer.pt\n",
            "Model fa_mwt exists in /root/.pernlp/fa_mwt.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file /root/.pernlp/ner.tar.gz: : 602MB [00:12, 48.2MB/s]                         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unziping the file ner.tar.gz\n",
            "[[('[CLS]', 'O'), ('این', 'O'), ('سریال', 'O'), ('به', 'O'), ('صورت', 'O'), ('رسمی', 'O'), ('در', 'O'), ('تاریخ', 'O'), ('دهم', 'B-date'), ('می', 'I-date'), ('۲۰۱۱', 'I-date'), ('توسط', 'O'), ('علی', 'B-person'), ('مرادی', 'I-person'), ('برای', 'O'), ('پخش', 'O'), ('رزرو', 'O'), ('شد', 'O'), ('!', 'O'), ('[SEP]', 'O')]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Persian NLP Datasets"
      ],
      "metadata": {
        "id": "Ze5DcdTXpaG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dadmatools.datasets import get_all_datasets_info, get_dataset_info\n",
        "from dadmatools.datasets import ARMAN\n",
        "from dadmatools.datasets import TEP\n",
        "from dadmatools.datasets import PerSentLexicon\n",
        "from dadmatools.datasets import FaSpell\n",
        "from dadmatools.datasets import WikipediaCorpus\n",
        "from dadmatools.datasets import PersianNer\n",
        "from dadmatools.datasets import PersianNews\n",
        "from dadmatools.datasets import PnSummary\n",
        "from dadmatools.datasets import FarsTail\n",
        "from dadmatools.datasets import SnappfoodSentiment\n",
        "from dadmatools.datasets import get_all_datasets_info\n",
        "from dadmatools.datasets import Peyma\n",
        "from dadmatools.datasets import PerUDT\n",
        "from dadmatools.datasets import PersianTweets\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "flEghMJ-pe_r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(get_all_datasets_info(tasks=['NER', 'Sentiment-Analysis']))"
      ],
      "metadata": {
        "id": "BNXBOfMopipK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf65473b-f6ad-48b7-d65a-943ed50586bd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ARMAN': {'description': 'ARMAN dataset holds 7,682 sentences with 250,015 '\n",
            "                          'sentences tagged over six different classes.\\n'\n",
            "                          '\\n'\n",
            "                          'Organization\\n'\n",
            "                          'Location\\n'\n",
            "                          'Facility\\n'\n",
            "                          'Event\\n'\n",
            "                          'Product\\n'\n",
            "                          'Person',\n",
            "           'filenames': ['train_fold1.txt',\n",
            "                         'train_fold2.txt',\n",
            "                         'train_fold3.txt',\n",
            "                         'test_fold1.txt',\n",
            "                         'test_fold2.txt',\n",
            "                         'test_fold3.txt'],\n",
            "           'name': 'ARMAN',\n",
            "           'size': {'test': 7680, 'train': 15361},\n",
            "           'splits': ['train', 'test'],\n",
            "           'task': 'NER',\n",
            "           'version': '1.0.0'},\n",
            " 'PersianNer': {'description': 'source: '\n",
            "                               'https://github.com/Text-Mining/Persian-NER',\n",
            "                'filenames': ['Persian-NER-part1.txt',\n",
            "                              'Persian-NER-part2.txt',\n",
            "                              'Persian-NER-part3.txt',\n",
            "                              'Persian-NER-part4.txt',\n",
            "                              'Persian-NER-part5.txt'],\n",
            "                'name': 'PersianNer',\n",
            "                'size': 976599,\n",
            "                'splits': [],\n",
            "                'task': 'NER',\n",
            "                'version': '1.0.0'},\n",
            " 'Peyma': {'description': 'source: '\n",
            "                          'http://nsurl.org/2019-2/tasks/task-7-named-entity-recognition-ner-for-farsi/',\n",
            "           'filenames': ['peyma/600K', 'peyma/300K'],\n",
            "           'name': 'Peyma',\n",
            "           'size': 10016,\n",
            "           'splits': [],\n",
            "           'task': 'NER',\n",
            "           'version': '1.0.0'},\n",
            " 'snappfoodSentiment': {'description': 'source: '\n",
            "                                       'https://huggingface.co/HooshvareLab/bert-fa-base-uncased-sentiment-snappfood',\n",
            "                        'filenames': ['snappfood/train.csv',\n",
            "                                      'snappfood/test.csv',\n",
            "                                      'snappfood/dev.csv'],\n",
            "                        'name': 'snappfoodSentiment',\n",
            "                        'size': {'dev': 6274, 'test': 6972, 'train': 56516},\n",
            "                        'splits': ['train', 'test', 'dev'],\n",
            "                        'task': 'Sentiment-Analysis',\n",
            "                        'version': '1.0.0'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(get_dataset_info('FarsTail'))"
      ],
      "metadata": {
        "id": "vrzrSXA8un9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec65718e-ac50-4d81-dffb-84f584dc6dbc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'description': 'source: https://github.com/dml-qom/FarsTail',\n",
            " 'filenames': ['Train-word.csv', 'Test-word.csv', 'Val-word.csv'],\n",
            " 'name': 'FarsTail',\n",
            " 'size': {'test': 1564, 'train': 7266, 'val': 1537},\n",
            " 'splits': ['train', 'test', 'val'],\n",
            " 'task': 'Textual-Entailment',\n",
            " 'version': '1.0.0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('*** WikipediaCorpus dataset ****')\n",
        "print()\n",
        "wiki = WikipediaCorpus()\n",
        "print('len data ', len(wiki.data))\n",
        "print()\n",
        "print('sample: ', next(wiki.data))\n",
        "print()\n",
        "print('****** dataset details:********\\n ')\n",
        "print(wiki.info)"
      ],
      "metadata": {
        "id": "ts30AhlMvCBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a69e64b-9228-4df8-acc0-bc2e6a5cb859"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** WikipediaCorpus dataset ****\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jHje8Q07tQWEpt8cEpFR_TOuqjFs79Vb\n",
            "To: /root/.dadmatools/datasets/WikipediaCorpus/wikipedia.tar.xz\n",
            "100%|██████████| 186M/186M [00:06<00:00, 26.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len data  2184117\n",
            "\n",
            "sample:  {'title': 'صفحهٔ اصلی', 'content': '&nbsp;مقاله\\u200cهای برگزیده &ndash; مقالهٔ امروز\\nامروز: ،  میلادی برابر  هجری خورشیدی و  (UTC)\\n→ روز قبل &ndash; روز بعد ←یادبودهای  &ndash; یادبودهای بیشتر...\\n بایگانی   &ndash; نگاره\\u200cهای برگزیدهٔ بیشتر\\n __NOTOC__ __NOEDITSECTION__'}\n",
            "\n",
            "****** dataset details:********\n",
            " \n",
            "name: WikipediaCorpus\n",
            "version: 20211201\n",
            "task: Corpus\n",
            "description: fawiki dump progress on 20211201 / All pages, current versions only.\n",
            "size: 2184117\n",
            "filenames: ['cleaned_wiki.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arman = ARMAN()\n",
        "print('**** Arman dataset **** ')\n",
        "print('splits: ', arman.info.splits)\n",
        "print(len(arman.train))\n",
        "print(next(arman.test))"
      ],
      "metadata": {
        "id": "OloJRC5LvDtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc52596c-3279-4bab-e8ce-c95f608fe823"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ArmanPersoNERCorpus.zip: 100%|██████████| 1.84M/1.84M [00:00<00:00, 37.0MB/s]\n",
            "**** Arman dataset **** \n",
            "splits:  ['train', 'test']\n",
            "15361\n",
            "[{'token': 'بنابراین', 'tag': 'O'}, {'token': 'نمی\\u200cشود', 'tag': 'O'}, {'token': 'با', 'tag': 'O'}, {'token': 'ارزشها', 'tag': 'O'}, {'token': 'شوخی', 'tag': 'O'}, {'token': 'کرد', 'tag': 'O'}, {'token': 'و', 'tag': 'O'}, {'token': 'باید', 'tag': 'O'}, {'token': 'آن', 'tag': 'O'}, {'token': 'را', 'tag': 'O'}, {'token': 'رعایت', 'tag': 'O'}, {'token': 'کرد', 'tag': 'O'}, {'token': '؛', 'tag': 'O'}, {'token': 'منتهی', 'tag': 'O'}, {'token': 'دو', 'tag': 'O'}, {'token': 'مسئله', 'tag': 'O'}, {'token': 'است', 'tag': 'O'}, {'token': ':', 'tag': 'O'}, {'token': 'اولا', 'tag': 'O'}, {'token': 'ارزشها', 'tag': 'O'}, {'token': 'چیستند', 'tag': 'O'}, {'token': '؟', 'tag': 'O'}, {'token': 'آیا', 'tag': 'O'}, {'token': 'هر', 'tag': 'O'}, {'token': 'برداشت', 'tag': 'O'}, {'token': 'ظاهربینانه', 'tag': 'O'}, {'token': 'سطحی\\u200cنگرایانه', 'tag': 'O'}, {'token': 'از', 'tag': 'O'}, {'token': 'دین', 'tag': 'O'}, {'token': 'يا', 'tag': 'O'}, {'token': 'از', 'tag': 'O'}, {'token': 'حیات', 'tag': 'O'}, {'token': 'اجتماعی', 'tag': 'O'}, {'token': 'و', 'tag': 'O'}, {'token': 'تحمیل', 'tag': 'O'}, {'token': 'آن', 'tag': 'O'}, {'token': 'به', 'tag': 'O'}, {'token': 'عنوان', 'tag': 'O'}, {'token': 'ارزش', 'tag': 'O'}, {'token': 'تشکیک\\u200cناپذیر', 'tag': 'O'}, {'token': 'درست', 'tag': 'O'}, {'token': 'است', 'tag': 'O'}, {'token': '؟', 'tag': 'O'}, {'token': 'آیا', 'tag': 'O'}, {'token': 'همه', 'tag': 'O'}, {'token': 'ارزشها', 'tag': 'O'}, {'token': 'یکسان', 'tag': 'O'}, {'token': 'در', 'tag': 'O'}, {'token': 'جامعه', 'tag': 'O'}, {'token': 'مطرح', 'tag': 'O'}, {'token': 'می\\u200cشوند', 'tag': 'O'}, {'token': '؟', 'tag': 'O'}, {'token': 'یعنی', 'tag': 'O'}, {'token': 'مثلا', 'tag': 'O'}, {'token': 'فرض', 'tag': 'O'}, {'token': 'کنید', 'tag': 'O'}, {'token': 'كه', 'tag': 'O'}, {'token': 'در', 'tag': 'O'}, {'token': 'جامعه', 'tag': 'O'}, {'token': 'اسلامی', 'tag': 'O'}, {'token': 'و', 'tag': 'O'}, {'token': 'مذهبی', 'tag': 'O'}, {'token': 'ما', 'tag': 'O'}, {'token': 'رعایت', 'tag': 'O'}, {'token': 'عفت', 'tag': 'O'}, {'token': 'عمومی', 'tag': 'O'}, {'token': '،', 'tag': 'O'}, {'token': 'اولا', 'tag': 'O'}, {'token': 'عفت', 'tag': 'O'}, {'token': 'را', 'tag': 'O'}, {'token': 'فقط', 'tag': 'O'}, {'token': 'جنبه', 'tag': 'O'}, {'token': 'ظاهری\\u200cاش', 'tag': 'O'}, {'token': 'بگیریم', 'tag': 'O'}, {'token': 'كه', 'tag': 'O'}, {'token': 'باید', 'tag': 'O'}, {'token': 'جنبه', 'tag': 'O'}, {'token': 'ظاهری\\u200cاش', 'tag': 'O'}, {'token': 'هم', 'tag': 'O'}, {'token': 'رعایت', 'tag': 'O'}, {'token': 'بشود', 'tag': 'O'}, {'token': '،', 'tag': 'O'}, {'token': 'جنبه\\u200cهای', 'tag': 'O'}, {'token': 'باطنی', 'tag': 'O'}, {'token': 'آن', 'tag': 'O'}, {'token': 'چه', 'tag': 'O'}, {'token': 'است', 'tag': 'O'}, {'token': '،', 'tag': 'O'}, {'token': 'در', 'tag': 'O'}, {'token': 'کنار', 'tag': 'O'}, {'token': 'آن', 'tag': 'O'}, {'token': 'جنبه\\u200cهای', 'tag': 'O'}, {'token': 'اخلاقی', 'tag': 'O'}, {'token': 'دیگر', 'tag': 'O'}, {'token': 'آیا', 'tag': 'O'}, {'token': 'رعایت', 'tag': 'O'}, {'token': 'می\\u200cشود', 'tag': 'O'}, {'token': '؟', 'tag': 'O'}, {'token': 'آیا', 'tag': 'O'}, {'token': 'غیبت', 'tag': 'O'}, {'token': '،', 'tag': 'O'}, {'token': 'آیا', 'tag': 'O'}, {'token': 'تخریب', 'tag': 'O'}, {'token': 'یکدیگر', 'tag': 'O'}, {'token': 'به', 'tag': 'O'}, {'token': 'عنوان', 'tag': 'O'}, {'token': 'مهمترین', 'tag': 'O'}, {'token': 'ضد', 'tag': 'O'}, {'token': 'ارزشهائی', 'tag': 'O'}, {'token': 'كه', 'tag': 'O'}, {'token': 'در', 'tag': 'O'}, {'token': 'جامعه', 'tag': 'O'}, {'token': 'ما', 'tag': 'O'}, {'token': 'احیانا', 'tag': 'O'}, {'token': 'هست', 'tag': 'O'}, {'token': 'و', 'tag': 'O'}, {'token': 'گاهی', 'tag': 'O'}, {'token': 'به', 'tag': 'O'}, {'token': 'جای', 'tag': 'O'}, {'token': 'ارزش', 'tag': 'O'}, {'token': 'مطرح', 'tag': 'O'}, {'token': 'می\\u200cشود', 'tag': 'O'}, {'token': '،', 'tag': 'O'}, {'token': 'مبارزه', 'tag': 'O'}, {'token': 'با', 'tag': 'O'}, {'token': 'اینها', 'tag': 'O'}, {'token': 'خودش', 'tag': 'O'}, {'token': 'دفاع', 'tag': 'O'}, {'token': 'از', 'tag': 'O'}, {'token': 'ارزشها', 'tag': 'O'}, {'token': 'نیست', 'tag': 'O'}, {'token': '؟', 'tag': 'O'}, {'token': 'گرچه', 'tag': 'O'}, {'token': 'ممکن', 'tag': 'O'}, {'token': 'است', 'tag': 'O'}, {'token': 'كه', 'tag': 'O'}, {'token': 'اگر', 'tag': 'O'}, {'token': 'بیائیم', 'tag': 'O'}, {'token': 'بگوئیم', 'tag': 'O'}, {'token': 'ریا', 'tag': 'O'}, {'token': '،', 'tag': 'O'}, {'token': 'تملق', 'tag': 'O'}, {'token': '،', 'tag': 'O'}, {'token': 'تخریب', 'tag': 'O'}, {'token': '،', 'tag': 'O'}, {'token': 'من', 'tag': 'O'}, {'token': 'اصلا', 'tag': 'O'}, {'token': 'جناحی', 'tag': 'O'}, {'token': 'صحبت', 'tag': 'O'}, {'token': 'نمی\\u200cکنم', 'tag': 'O'}, {'token': 'يك', 'tag': 'O'}, {'token': 'گله\\u200cای', 'tag': 'O'}, {'token': 'كه', 'tag': 'O'}, {'token': 'می\\u200cشود', 'tag': 'O'}, {'token': 'از', 'tag': 'O'}, {'token': 'همه', 'tag': 'O'}, {'token': 'روزنامه\\u200cها', 'tag': 'O'}, {'token': 'کرد', 'tag': 'O'}, {'token': '،', 'tag': 'O'}, {'token': 'این', 'tag': 'O'}, {'token': 'است', 'tag': 'O'}, {'token': 'كه', 'tag': 'O'}, {'token': 'چه', 'tag': 'O'}, {'token': 'ساده', 'tag': 'O'}, {'token': 'رقیب', 'tag': 'O'}, {'token': 'خود', 'tag': 'O'}, {'token': 'را', 'tag': 'O'}, {'token': 'تخریب', 'tag': 'O'}, {'token': 'می\\u200cکنند', 'tag': 'O'}, {'token': '،', 'tag': 'O'}, {'token': 'با', 'tag': 'O'}, {'token': 'حدسها', 'tag': 'O'}, {'token': 'با', 'tag': 'O'}, {'token': 'گمانها', 'tag': 'O'}, {'token': '،', 'tag': 'O'}, {'token': 'با', 'tag': 'O'}, {'token': 'بزرگ\\u200cسازیها', 'tag': 'O'}, {'token': '،', 'tag': 'O'}, {'token': 'با', 'tag': 'O'}, {'token': 'دروغ\\u200cپردازیها', 'tag': 'O'}, {'token': '.', 'tag': 'O'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Pre-Trained Persian Word Embeddings"
      ],
      "metadata": {
        "id": "YjjaqlIbqdV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install fastText"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "cbWTGKy2AgVx",
        "outputId": "1c665572-77a1-444e-8b49-bfeba2e7aa2d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastText\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.0-py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/site-packages (from fastText) (65.4.1)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fastText\n",
            "  Building wheel for fastText (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastText: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3325570 sha256=c80defd7761950054e2333172749da9a38fa350fb5d32c03e65a6f23fbd4c5c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fastText\n",
            "Installing collected packages: pybind11, numpy, fastText\n",
            "Successfully installed fastText-0.9.2 numpy-1.21.6 pybind11-2.10.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dadmatools.embeddings import get_embedding, get_all_embeddings_info, get_embedding_info"
      ],
      "metadata": {
        "id": "qxOYXRjxwRMw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(get_all_embeddings_info())"
      ],
      "metadata": {
        "id": "K2pxKNmQvGG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9fb6255-1f27-4eda-b0e6-aebdfba896b5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fasttext-commoncrawl-bin': {'algorithm': 'fasttext',\n",
            "                              'corpus': 'CommonCrawl',\n",
            "                              'desc': '',\n",
            "                              'dim': 300,\n",
            "                              'filename': 'cc.fa.300.bin',\n",
            "                              'format': 'bin',\n",
            "                              'url': 'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz'},\n",
            " 'fasttext-commoncrawl-vec': {'algorithm': 'fasttext',\n",
            "                              'corpus': 'CommonCrawl',\n",
            "                              'desc': '',\n",
            "                              'dim': 300,\n",
            "                              'filename': 'cc.fa.300.vec',\n",
            "                              'format': 'vec',\n",
            "                              'url': 'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.vec.gz'},\n",
            " 'glove-wiki': {'algorithm': 'glove',\n",
            "                'corpus': 'wikipedia',\n",
            "                'desc': 'source: https://github.com/Text-Mining',\n",
            "                'dim': 50,\n",
            "                'filename': 'vectors.txt',\n",
            "                'format': 'txt',\n",
            "                'url': 'https://raw.githubusercontent.com/Text-Mining/Persian-Wikipedia-Corpus/master/models/glove/vectors.zip'},\n",
            " 'word2vec-conll': {'algorithm': 'word2vec',\n",
            "                    'corpus': 'Persian CoNLL17 corpus',\n",
            "                    'desc': 'Word2Vec Continuous Skipgram',\n",
            "                    'dim': 100,\n",
            "                    'filename': 'model.bin',\n",
            "                    'format': 'bin',\n",
            "                    'url': 'http://vectors.nlpl.eu/repository/20/61.zip'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(get_embedding_info('glove-wiki'))"
      ],
      "metadata": {
        "id": "QJK2BIQyuoY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ada6701a-8cc6-4bea-8279-cbf1c3b12dba"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'algorithm': 'glove',\n",
            " 'corpus': 'wikipedia',\n",
            " 'desc': 'source: https://github.com/Text-Mining',\n",
            " 'dim': 50,\n",
            " 'filename': 'vectors.txt',\n",
            " 'format': 'txt',\n",
            " 'url': 'https://raw.githubusercontent.com/Text-Mining/Persian-Wikipedia-Corpus/master/models/glove/vectors.zip'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = get_embedding('glove-wiki')\n",
        "print(embedding['ابزار'])"
      ],
      "metadata": {
        "id": "sOY5kj6EvJWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35873319-da94-4bb5-8869-e06b0af0b3e9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vectors.zip: 100%|██████████| 45.9M/45.9M [00:00<00:00, 57.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2022-10-05 02:39:42,191 INFO] converting 240548 vectors from /root/.dadmatools/embeddings/glove-wiki/vectors.txt to /root/.dadmatools/embeddings/glove-wiki/vectors.txt_word2vec_format.vec\n",
            "[2022-10-05 02:39:42,562 INFO] loading projection weights from /root/.dadmatools/embeddings/glove-wiki/vectors.txt_word2vec_format.vec\n",
            "[2022-10-05 02:39:49,645 INFO] loaded (240548, 50) matrix from /root/.dadmatools/embeddings/glove-wiki/vectors.txt_word2vec_format.vec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.308614 -0.168945 -2.576352  0.877447 -0.348502  0.582602  0.602845\n",
            "  0.471903  0.533526  0.906185  0.907475 -0.167968 -0.095735 -0.475923\n",
            "  0.276284  0.010084 -0.926263 -1.124971 -0.443414 -0.447227  0.259192\n",
            "  0.078348  0.916888 -0.061847 -0.853357  0.996823 -0.26386   0.621702\n",
            "  0.768682  0.250663  0.358242  0.571274 -0.321239  0.012563 -0.567481\n",
            "  0.560345 -0.206234 -0.187835 -0.665903  0.234979 -0.442619  0.164727\n",
            " -0.262    -0.172979 -0.393394 -0.474647  0.480312  1.106502  0.767303\n",
            "  0.046918]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding.embedding_text('ابزار پردازش متن فارسی'))"
      ],
      "metadata": {
        "id": "LYQkhBotvLpP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e5ed20c-678d-43d9-c243-cba1dc70a847"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 8.2652763e-02  3.8418624e-01 -1.8762367e+00 -8.6866260e-02\n",
            "  3.6461627e-01  7.5215775e-01  3.6994025e-01  4.9959701e-01\n",
            "  1.2264743e-02  3.3335799e-01  5.5867076e-01  3.5873100e-01\n",
            "  4.2627126e-01 -8.8378501e-01 -1.2670399e-01 -7.0495725e-01\n",
            " -6.2538046e-01 -5.5862820e-01 -3.2012752e-01 -1.8887758e-02\n",
            "  2.8124401e-01  1.6167176e-01  5.9974694e-01  3.4806246e-01\n",
            " -1.4647543e-03  7.3103124e-01  1.9454075e-01  3.4274727e-01\n",
            "  5.1055348e-01  5.3316355e-01  5.8826029e-01  1.2634257e+00\n",
            " -1.2206910e+00 -4.0682977e-01 -2.4609923e-01  6.5093577e-01\n",
            " -2.5686526e-01 -4.0690476e-01  4.8100728e-01  4.8069999e-02\n",
            " -6.2497050e-01 -2.3815494e-02  2.1647224e-01 -2.1010575e-01\n",
            " -8.5227352e-01 -4.0755576e-01  8.1856251e-02  1.1975710e+00\n",
            "  5.1946604e-01  5.7960773e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.similarity('کتاب', 'کتب')"
      ],
      "metadata": {
        "id": "uMZKaHvuvNKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12080821-0046-44ef-a408-7f3d948801a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.77167135"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.similarity('کتاب', 'کتب')"
      ],
      "metadata": {
        "id": "tUvE4I8hvQpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e2f5c6-d06c-49e7-fdcf-1362815a4e47"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.77167135"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.top_nearest('کتاب', 10)"
      ],
      "metadata": {
        "id": "Ajdjq61fvRML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68b80a27-e578-434a-cfa4-b4ed57d2641f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2022-10-05 02:39:49,723 INFO] precomputing L2-norms of word weight vectors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('کتابی', 0.935340166091919),\n",
              " ('کتاب\\u200cهای', 0.8594834208488464),\n",
              " ('جلد', 0.8522472381591797),\n",
              " ('تالیف', 0.8399883508682251),\n",
              " ('نوشته', 0.8382428884506226),\n",
              " ('مقاله', 0.8335504531860352),\n",
              " ('نوشته\\u200cاست', 0.8273731470108032),\n",
              " ('شرح', 0.8273375630378723),\n",
              " ('ترجمه', 0.8256694078445435),\n",
              " ('می\\u200cنویسد', 0.8014417290687561)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uoU0JkfsA2xz"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}